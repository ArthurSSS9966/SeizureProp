{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# At the start of your notebook\n",
    "from IPython.display import clear_output\n",
    "import gc\n",
    "\n",
    "# After heavy computations\n",
    "clear_output(wait=True)\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a90337c9b40e83dc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from steps import setup_and_train_models, analyze_seizure_propagation\n",
    "import torch\n",
    "from datasetConstruct import construct_channel_recognition_dataset\n",
    "from models import Wavenet, train_using_optimizer\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a6fb54970056190",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "RESULT_FOLDER = \"result\"\n",
    "MODEL_FOLDER = \"model\"\n",
    "model_names = ['Wavenet']  # 'CNN1D', 'Wavenet', 'S4', 'Resnet'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f435e4429efe0ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from steps import extract_sEEG_features\n",
    "from datasetConstruct import load_seizure_across_patients, load_single_seizure\n",
    "\n",
    "dataset = load_seizure_across_patients(data_folder='data')\n",
    "\n",
    "for seizure in dataset:\n",
    "    seizure_new = extract_sEEG_features(seizure, sampling_rate=seizure.samplingRate)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6cae63b9e3c480d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results, models = setup_and_train_models(\n",
    "    data_folder=\"data\",\n",
    "    model_folder=\"checkpoints\",\n",
    "    model_names=model_names,\n",
    "    train=False,\n",
    "    input_type='transformed',  # 'transformed' or 'raw'\n",
    "    params={'epochs': 100, 'batch_size': 4096, 'checkpoint_freq': 20},  # params: epochs, checkpoint_freq, lr, batch_size, device, patience, gradient_clip\n",
    "    hyperparameter_search=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40278f619e39dba2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "from utils import split_data, find_seizure_related_channels\n",
    "from datasetConstruct import load_single_seizure\n",
    "from models import output_to_probability\n",
    "from steps import extract_sEEG_features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "marking_file = 'data/Seizure_Onset_Type_ML_USC.xlsx'\n",
    "patient_no = 66\n",
    "seizure_no = 1\n",
    "data_folder = 'data'\n",
    "# Set up paths\n",
    "single_seizure_folder = os.path.join(data_folder, f\"P{patient_no}\")\n",
    "save_folder = os.path.join(\"result\", f\"P{patient_no}\", f\"Seizure{seizure_no}\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "model_name = model_names[0]\n",
    "model = models[model_name]\n",
    "params = {\n",
    "    'threshold': 0.6,\n",
    "    'smooth_window': 30,\n",
    "    'n_seconds': 120,\n",
    "    'seizure_start': 60,\n",
    "    'overlap': 0.9,\n",
    "    'device': 'cuda:0'\n",
    "}\n",
    "\n",
    "def load_matter_file(folder: str) -> Dict:\n",
    "    \"\"\"Load Matter file for seizure\"\"\"\n",
    "    matter_file = os.path.join(folder, \"matter.csv\")\n",
    "    matter = pd.read_csv(matter_file)\n",
    "    return matter\n",
    "\n",
    "def load_seizure_data() -> Tuple[object, List[str], List[str]]:\n",
    "    \"\"\"Load seizure data and channel information\"\"\"\n",
    "    # Load seizure marking data\n",
    "    seizure_marking = pd.read_excel(marking_file)\n",
    "\n",
    "    # Find seizure-related channels\n",
    "    seizure_channels, seizure_onset_channels = find_seizure_related_channels(\n",
    "        seizure_marking, seizure_no, patient_no\n",
    "    )\n",
    "\n",
    "    # Load seizure data\n",
    "    seizure_obj = load_single_seizure(single_seizure_folder, seizure_no)\n",
    "\n",
    "    if not hasattr(seizure_obj, 'ictal_transformed'):\n",
    "        seizure_obj = extract_sEEG_features(seizure_obj, sampling_rate=seizure_obj.samplingRate)\n",
    "\n",
    "    # Load Matter file\n",
    "    if not hasattr(seizure_obj, 'matter'):\n",
    "        seizure_obj.matter = load_matter_file(single_seizure_folder)\n",
    "        \n",
    "    return seizure_obj, seizure_channels, seizure_onset_channels\n",
    "\n",
    "def process_data(seizure_obj) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    \"\"\"Process raw seizure data\"\"\"\n",
    "    fs = seizure_obj.samplingRate\n",
    "    if not hasattr(seizure_obj, 'ictal_transformed'):\n",
    "        ictal_data = seizure_obj.ictal_\n",
    "        preictal_data = seizure_obj.preictal2\n",
    "    \n",
    "        # Reshape and combine data\n",
    "        ictal_combined = ictal_data.reshape(-1, ictal_data.shape[2])\n",
    "        total_data = np.concatenate((preictal_data, ictal_combined), axis=0)\n",
    "    \n",
    "    else:\n",
    "        ictal_data = seizure_obj.ictal_transformed\n",
    "        preictal_data = seizure_obj.interictal_transformed\n",
    "        \n",
    "        # Reshape and combine data\n",
    "        ictal_combined = ictal_data.transpose(0, 2, 1, 3).reshape(ictal_data.shape[0]*ictal_data.shape[2], ictal_data.shape[1], ictal_data.shape[3])\n",
    "        preictal_data = preictal_data.transpose(0, 2, 1, 3).reshape(preictal_data.shape[0]*preictal_data.shape[2], preictal_data.shape[1], preictal_data.shape[3])\n",
    "        \n",
    "        total_data = np.concatenate((preictal_data, ictal_combined))\n",
    "\n",
    "    # Split data into windows\n",
    "    total_windows = split_data(total_data, 40, overlap=params['overlap'])\n",
    "\n",
    "    return total_data, total_windows, fs\n",
    "\n",
    "\n",
    "def compute_probabilities(data: np.ndarray, model, device: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute seizure probabilities for each channel.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : numpy.ndarray\n",
    "        Input data with shape (chunks, fs, channel) or (chunks, fs, channel, features)\n",
    "    model : torch model\n",
    "        The seizure detection model\n",
    "    device : str\n",
    "        The device to run the model on ('cpu' or 'cuda')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Probability matrix with shape (chunks, channel)\n",
    "    \"\"\"\n",
    "    # Determine if the input is 3D or 4D\n",
    "    is_4d = len(data.shape) == 4\n",
    "    \n",
    "    # Get dimensions\n",
    "    chunks = data.shape[0]\n",
    "    fs = data.shape[1]\n",
    "    n_channels = data.shape[2]\n",
    "    \n",
    "    # Initialize probability matrix\n",
    "    prob_matrix = np.zeros((chunks, n_channels))\n",
    "\n",
    "    for channel in range(n_channels):\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        if is_4d:\n",
    "            # 4D data: [chunks, fs, channel, features]\n",
    "            # Extract data for current channel\n",
    "            channel_data = data[:, :, channel, :]\n",
    "            \n",
    "            # Reshape for scaling: [chunks*fs, features]\n",
    "            original_shape = channel_data.shape\n",
    "            reshaped_data = channel_data.reshape(-1, original_shape[2])\n",
    "            \n",
    "            # Fit and transform the data\n",
    "            scaled_data = scaler.fit_transform(reshaped_data)\n",
    "            \n",
    "            # Reshape back\n",
    "            channel_data = scaled_data.reshape(original_shape)\n",
    "            \n",
    "            # Transpose for model input: [chunks, features, fs]\n",
    "            input_data = np.transpose(channel_data, (0, 2, 1))\n",
    "        else:\n",
    "            # 3D data: [chunks, fs, channel]\n",
    "            # Extract data for current channel\n",
    "            channel_data = data[:, :, channel]\n",
    "            \n",
    "            # Reshape for scaling: [chunks*fs, 1]\n",
    "            reshaped_data = channel_data.reshape(-1, 1)\n",
    "            \n",
    "            # Fit and transform the data\n",
    "            scaled_data = scaler.fit_transform(reshaped_data)\n",
    "            \n",
    "            # Reshape back to original shape and then to model input format\n",
    "            channel_data = scaled_data.reshape(chunks, fs)\n",
    "            input_data = channel_data.reshape(chunks, 1, fs)\n",
    "\n",
    "        # Convert to tensor and move to device\n",
    "        input_data = torch.tensor(input_data, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Compute probabilities\n",
    "        prob_matrix[:, channel] = output_to_probability(model, input_data, device)\n",
    "\n",
    "    return prob_matrix\n",
    "\n",
    "\n",
    "def extract_grey_matter_channels(matter: pd.DataFrame, seizure_channels: List[str]) -> List[str]:\n",
    "    \"\"\"Extract grey matter channels from Matter file\"\"\"\n",
    "    # Get grey matter channels\n",
    "    grey_matter = matter[matter['MatterType'] == 'G']\n",
    "    grey_matter_channels = grey_matter['ElectrodeName'].values\n",
    "    \n",
    "    # Find the intersection with seizure channels\n",
    "    grey_matter_channels = list(set(grey_matter_channels).intersection(seizure_channels))\n",
    "    \n",
    "    return grey_matter_channels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbe8d03956c9adb9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Test and debug single seizure data\n",
    "# Load data\n",
    "seizure_obj, seizure_channels, seizure_onset_channels = load_seizure_data()\n",
    "\n",
    "seizure_channels = extract_grey_matter_channels(seizure_obj.matter, seizure_channels)\n",
    "\n",
    "# Process data\n",
    "total_data, windowed_data, fs = process_data(seizure_obj)\n",
    "\n",
    "# # Compute probabilities\n",
    "probabilities = compute_probabilities(windowed_data, model, params['device'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b1eb3857ad72287",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "channel = 69\n",
    "seconds = 120\n",
    "preictal_seconds = 60\n",
    "preictal_samples = int((70-preictal_seconds)/(1-params['overlap']))\n",
    "nsamples = int(seconds/(1-params['overlap'])) + preictal_samples\n",
    "raw_data_ictal = seizure_obj.ictal\n",
    "raw_data_preicatal = seizure_obj.interictal\n",
    "\n",
    "# Reshape the data\n",
    "raw_data_ictal = raw_data_ictal.reshape(-1, raw_data_ictal.shape[2])[:(seconds-10)*512]\n",
    "raw_data_preicatal = raw_data_preicatal.reshape(-1, raw_data_preicatal.shape[2])[-preictal_seconds*512:]\n",
    "\n",
    "# Combine the data\n",
    "raw_data = np.concatenate((raw_data_preicatal, raw_data_ictal), axis=0)\n",
    "raw_data = raw_data[:, channel]\n",
    "# Plot the total data and seizure probability\n",
    "feature_data = np.mean(windowed_data, axis=1)[:, channel][preictal_samples:nsamples]\n",
    "\n",
    "# Scale the raw data\n",
    "scaler = StandardScaler()\n",
    "feature_data = scaler.fit_transform(feature_data)\n",
    "probability = probabilities[:, channel][preictal_samples:nsamples]\n",
    "\n",
    "# Smooth the probability by using a moving average\n",
    "probability = np.convolve(probability, np.ones(params['smooth_window']) / params['smooth_window'], mode='same')\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 6))\n",
    "ax[0].plot(feature_data)\n",
    "ax[1].plot(raw_data)\n",
    "ax[2].plot(probability)\n",
    "ax[2].axhline(params['threshold'], color='red', linestyle='--')\n",
    "ax[0].set_title(f'Channel {channel+1} - Feature Data')\n",
    "ax[1].set_title(f'Channel {channel+1} - Raw Data')\n",
    "x_ticks = np.linspace(0, len(raw_data), len(raw_data)//5120)\n",
    "x_labels = np.linspace(0, seconds, len(x_ticks))\n",
    "ax[1].set_xticks(x_ticks)\n",
    "ax[1].set_xticklabels(x_labels)\n",
    "ax[2].set_title(f'Channel {channel+1} - Seizure Probability')\n",
    "# Set x-axis labels\n",
    "ax[2].set_xlabel('Time (s)')\n",
    "# Change x-ticks to seconds\n",
    "x_ticks = np.arange(0, nsamples-preictal_samples, 100)\n",
    "x_labels = np.arange(0, seconds, 10)\n",
    "ax[2].set_xticks(x_ticks)\n",
    "ax[2].set_xticklabels(x_labels)\n",
    "\n",
    "# Delete ax[0] x-axis labels\n",
    "ax[0].set_xticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b073b8eee2345485",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Do batch analysis to find the best hyperparameters\n",
    "seizures = [1,2,3,4,5,6,7]\n",
    "thresholds = [0.5, 0.6, 0.8, 0.9]\n",
    "smooth_windows = [30, 50, 80]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "259a06cb946a7615",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results_propagation_total = []\n",
    "model_name = model_names[0]\n",
    "model = models[model_name]\n",
    "threshold = 0.6\n",
    "smooth_window = 30\n",
    "LOAD=False\n",
    "filename = f'{RESULT_FOLDER}/results_propagation_{model_name}_{threshold}_{smooth_window}.pkl'\n",
    "\n",
    "# if file exists\n",
    "if os.path.exists(filename) and LOAD:\n",
    "    with open(filename, 'rb') as f:\n",
    "        results_propagation_total = pickle.load(f)\n",
    "        \n",
    "if len(results_propagation_total) == 0:\n",
    "    for PAT_NO in [65, 66]:\n",
    "        for seizure_no in seizures:\n",
    "            if (PAT_NO == 65 and seizure_no == 2) or (PAT_NO == 65 and seizure_no == 4) or (PAT_NO == 65 and seizure_no == 6):\n",
    "                continue\n",
    "            params = {\n",
    "                'threshold': threshold,\n",
    "                'smooth_window': smooth_window,\n",
    "                'n_seconds': 60,\n",
    "                'seizure_start': 70,\n",
    "            }\n",
    "            results_propagation = analyze_seizure_propagation(\n",
    "                patient_no=PAT_NO,\n",
    "                seizure_no=seizure_no,\n",
    "                model=model,\n",
    "                data_folder='data',\n",
    "                params=params,\n",
    "                save_results_ind=True\n",
    "            )\n",
    "            results_propagation_total.append(results_propagation)\n",
    "            \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(results_propagation_total, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14ccef415a934e81",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seizure_66_result = [0.733, 1, 0.91, 0.8, 0.8, 0.91, 0.91]\n",
    "seizure_65_result = [0.81, 0.75, 0.63, 0.75, 0.81]\n",
    "seizure_66_prev_result = [0.65, 0.91, 0.73, 0.61, 0.55, 0.73, 0.55]\n",
    "seizure_65_prev_result = [0.53, 0.22, 0.63, 0.56, 0.19]\n",
    "\n",
    "# Do statistical test between the current and previous results\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "t_statistic_65, p_value_65 = ttest_rel(seizure_65_result, seizure_65_prev_result)\n",
    "print(f'Patient 65: t-statistic: {t_statistic_65}, p-value: {p_value_65}')\n",
    "\n",
    "t_statistic_66, p_value_66 = ttest_rel(seizure_66_result, seizure_66_prev_result)\n",
    "print(f'Patient 66: t-statistic: {t_statistic_66}, p-value: {p_value_66}')\n",
    "\n",
    "# Plot the result in a box plot for each patient\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].boxplot([seizure_65_result, seizure_65_prev_result], labels=['Current', 'Previous'])\n",
    "ax[0].set_title('Patient 65 (N=5)')\n",
    "ax[0].set_ylabel('Prediction Accuracy')\n",
    "# Plot the statistical difference as asterisk\n",
    "if p_value_65 < 0.05:\n",
    "    ax[0].text(1.5, 1.12, '*', fontsize=12, color='red')\n",
    "    ax[0].hlines(1.1, 1, 2, color='red')\n",
    "ax[0].set_ylim(0, 1.3)\n",
    "ax[1].boxplot([seizure_66_result, seizure_66_prev_result], labels=['Current', 'Previous'])\n",
    "ax[1].set_title('Patient 66 (N=7)')\n",
    "ax[1].set_ylabel('Prediction Accuracy')\n",
    "# Plot the statistical difference as asterisk\n",
    "if p_value_66 < 0.005:\n",
    "    ax[1].text(1.5, 1.12, '***', fontsize=12, color='red')\n",
    "    ax[1].hlines(1.1, 1, 2, color='red')\n",
    "ax[1].set_ylim(0, 1.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('result/propagation_accuracy.svg')\n",
    "plt.savefig('result/propagation_accuracy.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf9aca0b8a57949c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Examine the result:\n",
    "from plotFun import plot_eeg_style\n",
    "# 1. Plot the smoothed result:\n",
    "sample_result = results_propagation_total[5]['smoothed_probabilities'][20:350]\n",
    "sample_result2 = results_propagation_total[5]['probabilities'][20:300]\n",
    "fig = plot_eeg_style(sample_result.T, sampling_rate=5)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27e1254bfb1f8896",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seizure_channels_dataset_train, seizure_channels_dataset_val, seizure_onset_dataset_train, seizure_onset_dataset_val = construct_channel_recognition_dataset(results_propagation_total, 50, batch_size=128, data_aug=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26997a5ef8715da0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_seizure_channel = Wavenet(input_dim=1, output_dim=2, lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_loss, val_loss, val_accuracy = train_using_optimizer(model_seizure_channel, seizure_channels_dataset_train, seizure_channels_dataset_val, epochs=200, checkpoint_freq=20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28e4375eb57ea2fd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "\n",
    "x_ticks = range(0, 200, 20)\n",
    "\n",
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(x_ticks, val_loss, label='Validation')\n",
    "# Twin the y-axis for accuracy of validation\n",
    "plt.twinx()\n",
    "plt.plot(x_ticks, val_accuracy, label='Validation Accuracy', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('result/loss_seizure_channels.png')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64dde4dc9514e03f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predicted_labels_total = []\n",
    "\n",
    "time_lengths = [10, 20, 30, 40, 50, 60]\n",
    "\n",
    "for i in range(len(results_propagation_total)):\n",
    "\n",
    "    sample_seizure = results_propagation_total[i]['smoothed_probabilities'][50:300, :]\n",
    "    \n",
    "    # Feed the data to the model and get predictions\n",
    "    sample_seizure = sample_seizure.T\n",
    "    sample_seizure = np.expand_dims(sample_seizure, axis=1)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    sample_seizure = torch.tensor(sample_seizure, dtype=torch.float32)\n",
    "    \n",
    "    # Get the predictions\n",
    "    predictions = model_seizure_channel(sample_seizure)\n",
    "    \n",
    "    # Get the predicted labels, where predicted_labels = 1 when chance is more than 80%\n",
    "    predicted_labels = predictions.detach().to('cpu').numpy()\n",
    "    \n",
    "    predicted_labels = predicted_labels[:, 1] > 0.5\n",
    "    \n",
    "    predicted_labels_total.append(predicted_labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22895f03a8fee345",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Convert the channel from results_propagation to the y_true as 1s and 0s\n",
    "gound_truth_total = []\n",
    "for i in range(len(results_propagation_total)):\n",
    "    y_true = np.zeros(results_propagation_total[i]['smoothed_probabilities'].shape[1])\n",
    "    y_true[results_propagation_total[i]['true_seizure_channels']] = 1\n",
    "    gound_truth_total.append(y_true)\n",
    "    \n",
    "# Convert the gound_truth_total to a single array\n",
    "gound_truth_total = np.concatenate(gound_truth_total)\n",
    "\n",
    "# Convert the predicted_labels_total to a single array\n",
    "predicted_labels_total = np.concatenate(predicted_labels_total)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3093baf9d7c09ff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(gound_truth_total.flatten(), predicted_labels_total.flatten())\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig('result/confusion_matrix_seizure_channels.png')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c711468730b53833",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(gound_truth_total.flatten(), predicted_labels_total.flatten())\n",
    "precision = precision_score(gound_truth_total.flatten(), predicted_labels_total.flatten())\n",
    "recall = recall_score(gound_truth_total.flatten(), predicted_labels_total.flatten())\n",
    "f1 = f1_score(gound_truth_total.flatten(), predicted_labels_total.flatten())\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd869a20d7728b23",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "364f74876053c6f0",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
