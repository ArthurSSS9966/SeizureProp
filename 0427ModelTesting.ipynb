{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# At the start of your notebook\n",
    "from IPython.display import clear_output\n",
    "import gc\n",
    "\n",
    "# After heavy computations\n",
    "clear_output(wait=True)\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a90337c9b40e83dc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "RESULT_FOLDER = \"result\"\n",
    "MODEL_FOLDER = \"model\"\n",
    "model_names = ['Wavenet']  # 'CNN1D', 'Wavenet', 'S4', 'Resnet'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f435e4429efe0ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from steps import extract_sEEG_features\n",
    "from datasetConstruct import load_seizure_across_patients\n",
    "\n",
    "dataset = load_seizure_across_patients(data_folder='data')\n",
    "\n",
    "# for seizure in dataset:\n",
    "#     seizure_new = extract_sEEG_features(seizure, sampling_rate=seizure.samplingRate)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6cae63b9e3c480d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from models import EnhancedResNet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40278f619e39dba2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "EnhancedResNet 单元测试\n",
    "这个 Notebook 包含了对 EnhancedResNet 模型的单元测试，专门设计用于验证模型在癫痫发作数据上的性能。\n",
    "## 测试内容包括\n",
    "1. 模型初始化测试\n",
    "2. 前向传播测试\n",
    "3. 损失函数测试 (解剖约束损失、癫痫通道损失)\n",
    "4. 模型收敛测试\n",
    "5. 真实数据测试"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fec95b1b0467e06"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import unittest\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the necessary modules from your code\n",
    "from steps import train_using_optimizer_with_masks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a793a2c30ea792a6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SyntheticSeizureDataset(Dataset):\n",
    "    def __init__(self, data, labels, seizure_mask, grey_matter_values, channel_idx, time_idx):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.seizure_mask = torch.tensor(seizure_mask, dtype=torch.bool)\n",
    "        self.grey_matter_values = torch.tensor(grey_matter_values, dtype=torch.float32)\n",
    "        self.channel_idx = torch.tensor(channel_idx, dtype=torch.long)\n",
    "        self.time_idx = torch.tensor(time_idx, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'data': self.data[idx],  # Shape: (1, time_steps)\n",
    "            'label': self.labels[idx],\n",
    "            'seizure_mask': self.seizure_mask[idx],\n",
    "            'grey_matter_values': self.grey_matter_values[idx],\n",
    "            'channel_idx': self.channel_idx[idx],\n",
    "            'time_idx': self.time_idx[idx]\n",
    "        }\n",
    "\n",
    "\n",
    "def create_synthetic_seizure_data(n_samples=64, n_channels=40, time_steps=128, batch_size=16, feature_dim=11):\n",
    "    \"\"\"\n",
    "    Generate synthetic seizure dataset with expanded feature dimension.\n",
    "    \"\"\"\n",
    "    grey_matter_map = np.zeros(n_channels)\n",
    "    grey_matter_map[:20] = 1.0\n",
    "    grey_matter_map[20:25] = 0.5\n",
    "    grey_matter_map[25:] = 0.0\n",
    "\n",
    "    all_samples = []\n",
    "    all_labels = []\n",
    "    all_seizure_masks = []\n",
    "    all_grey_matter_values = []\n",
    "    all_channel_indices = []\n",
    "    all_time_indices = []\n",
    "\n",
    "    for sample_idx in range(n_samples):\n",
    "        if sample_idx < n_samples // 2:\n",
    "            label = 1\n",
    "            t = np.linspace(0, 1, time_steps)\n",
    "            base_signal = np.sin(2 * np.pi * 20 * t) + 0.5*np.sin(2*np.pi*40*t) + 0.2*np.random.randn(time_steps)\n",
    "        else:\n",
    "            label = 0\n",
    "            t = np.linspace(0, 1, time_steps)\n",
    "            base_signal = 0.5*np.sin(2*np.pi*5*t) + 0.2*np.sin(2*np.pi*10*t) + 0.3*np.random.randn(time_steps)\n",
    "\n",
    "        for ch_idx in range(n_channels):\n",
    "            feature_matrix = np.zeros((feature_dim, time_steps))\n",
    "            for f in range(feature_dim):\n",
    "                feature_matrix[f] = base_signal + 0.01*np.random.randn(time_steps)\n",
    "\n",
    "            all_samples.append(feature_matrix)\n",
    "            all_labels.append(label)\n",
    "            all_grey_matter_values.append(grey_matter_map[ch_idx])\n",
    "            all_channel_indices.append(ch_idx)\n",
    "            all_time_indices.append(sample_idx)\n",
    "\n",
    "            if label == 1 and ch_idx < 8:\n",
    "                all_seizure_masks.append(1)\n",
    "            else:\n",
    "                all_seizure_masks.append(0)\n",
    "\n",
    "    all_samples = np.stack(all_samples)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_seizure_masks = np.array(all_seizure_masks)\n",
    "    all_grey_matter_values = np.array(all_grey_matter_values)\n",
    "    all_channel_indices = np.array(all_channel_indices)\n",
    "    all_time_indices = np.array(all_time_indices)\n",
    "\n",
    "    idx = np.random.permutation(len(all_samples))\n",
    "    all_samples = all_samples[idx]\n",
    "    all_labels = all_labels[idx]\n",
    "    all_seizure_masks = all_seizure_masks[idx]\n",
    "    all_grey_matter_values = all_grey_matter_values[idx]\n",
    "    all_channel_indices = all_channel_indices[idx]\n",
    "    all_time_indices = all_time_indices[idx]\n",
    "\n",
    "    split = int(0.8 * len(all_samples))\n",
    "    train_dataset = SyntheticSeizureDataset(\n",
    "        all_samples[:split], all_labels[:split], all_seizure_masks[:split],\n",
    "        all_grey_matter_values[:split], all_channel_indices[:split], all_time_indices[:split]\n",
    "    )\n",
    "    val_dataset = SyntheticSeizureDataset(\n",
    "        all_samples[split:], all_labels[split:], all_seizure_masks[split:],\n",
    "        all_grey_matter_values[split:], all_channel_indices[split:], all_time_indices[split:]\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "# Create synthetic data\n",
    "train_loader, val_loader = create_synthetic_seizure_data(\n",
    "    n_samples=64, \n",
    "    n_channels=40, \n",
    "    time_steps=128,\n",
    "    batch_size=16\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48902e1affb0d686",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test_model_initialization():\n",
    "    \"\"\"Test that the model initializes correctly\"\"\"\n",
    "    # Define model parameters\n",
    "    input_dim = 11  # Number of features\n",
    "    output_dim = 2  # Binary classification\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Create a model instance\n",
    "    model = EnhancedResNet(\n",
    "        input_dim=input_dim,\n",
    "        output_dim=output_dim,\n",
    "        base_filters=32,\n",
    "        n_blocks=3,\n",
    "        kernel_size=16,\n",
    "        dropout=0.2,\n",
    "        lr=0.001,\n",
    "        weight_decay=1e-5,\n",
    "    )\n",
    "    \n",
    "    # Check model parameters\n",
    "    assert model.input_dim == input_dim, f\"Expected input_dim {input_dim}, got {model.input_dim}\"\n",
    "    assert model.output_dim == output_dim, f\"Expected output_dim {output_dim}, got {model.output_dim}\"\n",
    "    print(\"Model initialization test passed!\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Run the test\n",
    "model = test_model_initialization()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56cd430114cd2f95",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test_convergence_on_synthetic_data(model, epochs=10):\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    print(f\"Using temporary directory: {temp_dir}\")\n",
    "\n",
    "    n_channels = 40\n",
    "    time_steps = 128\n",
    "    batch_size = 16\n",
    "\n",
    "    train_loader, val_loader = create_synthetic_seizure_data(\n",
    "        n_samples=64,\n",
    "        n_channels=n_channels,\n",
    "        time_steps=time_steps,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    train_loss, val_loss, val_accuracy = train_using_optimizer_with_masks(\n",
    "        model=model,\n",
    "        trainloader=train_loader,\n",
    "        valloader=val_loader,\n",
    "        save_location=temp_dir,\n",
    "        epochs=epochs,\n",
    "        device=device,\n",
    "        patience=5,\n",
    "        scheduler_patience=3,\n",
    "        checkpoint_freq=5\n",
    "    )\n",
    "\n",
    "    assert train_loss[-1] < train_loss[0], f\"Training loss didn't decrease: {train_loss[0]} -> {train_loss[-1]}\"\n",
    "    assert val_accuracy[-1] > 0.5, f\"Validation accuracy didn't improve above random: {val_accuracy[-1]}\"\n",
    "\n",
    "    print(f\"Initial training loss: {train_loss[0]:.4f}\")\n",
    "    print(f\"Final training loss: {train_loss[-1]:.4f}\")\n",
    "    print(f\"Initial validation accuracy: {val_accuracy[0]:.4f}\")\n",
    "    print(f\"Final validation accuracy: {val_accuracy[-1]:.4f}\")\n",
    "    print(\"Convergence test passed!\")\n",
    "\n",
    "    for file in os.listdir(temp_dir):\n",
    "        os.remove(os.path.join(temp_dir, file))\n",
    "    os.rmdir(temp_dir)\n",
    "\n",
    "    return train_loss, val_loss, val_accuracy\n",
    "\n",
    "# Example run\n",
    "model = EnhancedResNet(input_dim=11, output_dim=2)  # Example model\n",
    "train_loss, val_loss, val_accuracy = test_convergence_on_synthetic_data(model, epochs=5)\n",
    "\n",
    "# Plotting\n",
    "def plot_training_curves(train_loss, val_loss, val_accuracy):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53fbec4ef729c538",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test_real_seizure_data_convergence(\n",
    "    model, \n",
    "    patient_no=65, \n",
    "    seizure_no=3, \n",
    "    data_folder=\"data\", \n",
    "    epochs=5, \n",
    "    batch_size=128, \n",
    "    input_type='transformed',\n",
    "    clean_up=True\n",
    "):\n",
    "    \"\"\"Test model convergence on a real seizure data sample\"\"\"\n",
    "    import tempfile, os\n",
    "    try:\n",
    "        from steps import load_single_seizure, create_dataset\n",
    "        \n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        print(f\"Using temporary directory: {temp_dir}\")\n",
    "    \n",
    "        device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        single_seizure_folder = os.path.join(data_folder, f\"P{patient_no}\")\n",
    "    \n",
    "        if not os.path.exists(single_seizure_folder):\n",
    "            print(f\"No seizure data found for patient {patient_no}\")\n",
    "            return None, None, None\n",
    "    \n",
    "        print(f\"Loading seizure {seizure_no} for patient {patient_no}\")\n",
    "        seizure_obj = load_single_seizure(single_seizure_folder, seizure_no)\n",
    "    \n",
    "        # create dataset\n",
    "        train_loader, val_loader = create_dataset(\n",
    "            seizure=seizure_obj,\n",
    "            train_percentage=0.8,\n",
    "            batch_size=batch_size,\n",
    "            input_type=input_type\n",
    "        )\n",
    "    \n",
    "        # Optional: reset model weights if needed\n",
    "        model.train()\n",
    "    \n",
    "        # Train\n",
    "        train_loss, val_loss, val_accuracy = train_using_optimizer_with_masks(\n",
    "            model=model,\n",
    "            trainloader=train_loader,\n",
    "            valloader=val_loader,\n",
    "            save_location=temp_dir,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            patience=3,\n",
    "            scheduler_patience=2,\n",
    "            checkpoint_freq=2\n",
    "        )\n",
    "    \n",
    "        # Assertions\n",
    "        assert train_loss[-1] < train_loss[0], f\"Training loss didn't decrease: {train_loss[0]} -> {train_loss[-1]}\"\n",
    "        assert val_accuracy[-1] > 0.5, f\"Validation accuracy didn't improve above random: {val_accuracy[-1]}\"\n",
    "    \n",
    "        print(f\"Initial Training Loss: {train_loss[0]:.4f} -> Final: {train_loss[-1]:.4f}\")\n",
    "        print(f\"Initial Validation Accuracy: {val_accuracy[0]:.4f} -> Final: {val_accuracy[-1]:.4f}\")\n",
    "        print(\"Real data convergence test passed!\")\n",
    "    \n",
    "        if clean_up:\n",
    "            for file in os.listdir(temp_dir):\n",
    "                os.remove(os.path.join(temp_dir, file))\n",
    "            os.rmdir(temp_dir)\n",
    "    \n",
    "        return train_loss, val_loss, val_accuracy\n",
    "        \n",
    "    except (ImportError, ModuleNotFoundError) as e:\n",
    "        print(f\"Required modules not available for real data testing: {e}\")\n",
    "        return None, None, None\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Real seizure data not available for testing: {e}\")\n",
    "        return None, None, None\n",
    "    finally:\n",
    "        # Clean up temporary directory\n",
    "        if os.path.exists(temp_dir):\n",
    "            for file in os.listdir(temp_dir):\n",
    "                os.remove(os.path.join(temp_dir, file))\n",
    "            os.rmdir(temp_dir)\n",
    "model = EnhancedResNet(\n",
    "    input_dim=11,\n",
    "    output_dim=2,\n",
    "    base_filters=32,\n",
    "    n_blocks=3,\n",
    "    kernel_size=16,\n",
    "    dropout=0.2,\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "# Run the test\n",
    "real_train_loss, real_val_loss, real_val_accuracy = test_real_seizure_data_convergence(model)\n",
    "\n",
    "# Plot training curves if data is available\n",
    "if real_train_loss is not None:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(real_train_loss, label='Training Loss')\n",
    "    plt.plot(real_val_loss, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss Curves (Real Data)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(real_val_accuracy, label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy (Real Data)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cfcc176b5e63e6c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from steps import setup_and_train_models\n",
    "\n",
    "results, models = setup_and_train_models(\n",
    "    data_folder=\"data\",\n",
    "    model_folder=\"checkpoints\",\n",
    "    model_names=['EnhancedResNet'],\n",
    "    train=True,\n",
    "    input_type='transformed',  # 'transformed' or 'raw'\n",
    "    params={'epochs': 100, 'batch_size': 2048, 'checkpoint_freq': 20},  # params: epochs, checkpoint_freq, lr, batch_size, device, patience, gradient_clip\n",
    "    hyperparameter_search=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc1d5eb24a596f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test_performance_with_and_without_constraints(epochs=5):\n",
    "    \"\"\"Compare model performance with and without anatomical constraints\"\"\"\n",
    "    # Create temporary directory for model checkpoints\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    temp_dir_with = os.path.join(temp_dir, \"with_constraints\")\n",
    "    temp_dir_without = os.path.join(temp_dir, \"without_constraints\")\n",
    "    os.makedirs(temp_dir_with, exist_ok=True)\n",
    "    os.makedirs(temp_dir_without, exist_ok=True)\n",
    "    \n",
    "    # Set device\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create synthetic seizure data\n",
    "    n_channels = 32\n",
    "    time_steps = 128\n",
    "    batch_size = 16\n",
    "    train_loader, val_loader = create_synthetic_seizure_data(\n",
    "        n_samples=64, \n",
    "        n_channels=n_channels, \n",
    "        time_steps=time_steps,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # First, train the model with constraints\n",
    "        model_with = EnhancedResNet(\n",
    "            input_dim=12,\n",
    "            output_dim=2,\n",
    "            base_filters=32,\n",
    "            n_blocks=3,\n",
    "            kernel_size=16,\n",
    "            dropout=0.2,\n",
    "            lr=0.001,\n",
    "            weight_decay=1e-5,\n",
    "            gamma=0.5  # Weight for anatomical constraint\n",
    "        )\n",
    "        \n",
    "        print(\"Training model WITH anatomical constraints...\")\n",
    "        train_loss_with, val_loss_with, val_accuracy_with = train_using_optimizer_with_masks(\n",
    "            model=model_with,\n",
    "            trainloader=train_loader,\n",
    "            valloader=val_loader,\n",
    "            save_location=temp_dir_with,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            patience=5,\n",
    "            scheduler_patience=3,\n",
    "            checkpoint_freq=epochs\n",
    "        )\n",
    "        \n",
    "        # Next, train the model without constraints\n",
    "        model_without = EnhancedResNet(\n",
    "            input_dim=12,\n",
    "            output_dim=2,\n",
    "            base_filters=32,\n",
    "            n_blocks=3,\n",
    "            kernel_size=16,\n",
    "            dropout=0.2,\n",
    "            lr=0.001,\n",
    "            weight_decay=1e-5,\n",
    "            gamma=0.0  # No anatomical constraint\n",
    "        )\n",
    "        \n",
    "        print(\"\\nTraining model WITHOUT anatomical constraints...\")\n",
    "        train_loss_without, val_loss_without, val_accuracy_without = train_using_optimizer_with_masks(\n",
    "            model=model_without,\n",
    "            trainloader=train_loader,\n",
    "            valloader=val_loader,\n",
    "            save_location=temp_dir_without,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            patience=5,\n",
    "            scheduler_patience=3,\n",
    "            checkpoint_freq=epochs\n",
    "        )\n",
    "        \n",
    "        # Print comparison results\n",
    "        print(\"\\n--- Performance Comparison ---\")\n",
    "        print(f\"WITH constraints - Final val accuracy: {val_accuracy_with[-1]:.4f}\")\n",
    "        print(f\"WITHOUT constraints - Final val accuracy: {val_accuracy_without[-1]:.4f}\")\n",
    "        \n",
    "        # Plot comparison\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(train_loss_with, label='With Constraints')\n",
    "        plt.plot(train_loss_without, label='Without Constraints')\n",
    "        plt.legend()\n",
    "        plt.title('Training Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(val_loss_with, label='With Constraints')\n",
    "        plt.plot(val_loss_without, label='Without Constraints')\n",
    "        plt.legend()\n",
    "        plt.title('Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(val_accuracy_with, label='With Constraints')\n",
    "        plt.plot(val_accuracy_without, label='Without Constraints')\n",
    "        plt.legend()\n",
    "        plt.title('Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return (\n",
    "            (train_loss_with, val_loss_with, val_accuracy_with),\n",
    "            (train_loss_without, val_loss_without, val_accuracy_without)\n",
    "        )\n",
    "        \n",
    "    finally:\n",
    "        # Clean up temporary directory\n",
    "        if os.path.exists(temp_dir):\n",
    "            for subdir in [temp_dir_with, temp_dir_without]:\n",
    "                if os.path.exists(subdir):\n",
    "                    for file in os.listdir(subdir):\n",
    "                        os.remove(os.path.join(subdir, file))\n",
    "                    os.rmdir(subdir)\n",
    "            os.rmdir(temp_dir)\n",
    "\n",
    "# Run the comparison test with fewer epochs for quicker testing\n",
    "results_with, results_without = test_performance_with_and_without_constraints(epochs=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "817a1398385aab2d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "865ee70f383a5c0c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
