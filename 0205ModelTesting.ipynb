{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# At the start of your notebook\n",
    "from IPython.display import clear_output\n",
    "import gc\n",
    "\n",
    "# After heavy computations\n",
    "clear_output(wait=True)\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a90337c9b40e83dc",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[KeOps] Warning : There were warnings or errors compiling formula :\n",
      "CMake Warning (dev) at CMakeLists.txt:24 (find_package):\n",
      "  Policy CMP0146 is not set: The FindCUDA module is removed.  Run \"cmake\n",
      "  --help-policy CMP0146\" for policy details.  Use the cmake_policy command to\n",
      "  set the policy and suppress this warning.\n",
      "\n",
      "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\n",
      "CUDA_CUDART_LIBRARY = C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8/lib/x64/cudart.lib\n",
      "CUDA_LIBRARIES = C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8/lib/x64/cudart_static.lib\n",
      "CUDA_TOOLKIT_ROOT_DIR = C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8\n",
      "set nvrtc path = C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8/lib/x64\n",
      "CMake Warning (dev) at C:/Users/arthu/anaconda3/envs/seizure/Lib/site-packages/pybind11/share/cmake/pybind11/FindPythonLibsNew.cmake:101 (message):\n",
      "  Policy CMP0148 is not set: The FindPythonInterp and FindPythonLibs modules\n",
      "  are removed.  Run \"cmake --help-policy CMP0148\" for policy details.  Use\n",
      "  the cmake_policy command to set the policy and suppress this warning, or\n",
      "  preferably upgrade to using FindPython, either by calling it explicitly\n",
      "  before pybind11, or by setting PYBIND11_FINDPYTHON ON before pybind11.\n",
      "Call Stack (most recent call first):\n",
      "  C:/Users/arthu/anaconda3/envs/seizure/Lib/site-packages/pybind11/share/cmake/pybind11/pybind11Tools.cmake:50 (find_package)\n",
      "  C:/Users/arthu/anaconda3/envs/seizure/Lib/site-packages/pybind11/share/cmake/pybind11/pybind11Common.cmake:228 (include)\n",
      "  C:/Users/arthu/anaconda3/envs/seizure/Lib/site-packages/pybind11/share/cmake/pybind11/pybind11Config.cmake:250 (include)\n",
      "  CMakeLists.txt:37 (find_package)\n",
      "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\n",
      "pybind11_INCLUDE_DIRS = C:/Users/arthu/anaconda3/envs/seizure/Lib/site-packages/pybind11/include;C:/Users/arthu/anaconda3/envs/seizure/Include\n",
      "PYTHON_LIBRARY = C:/Users/arthu/anaconda3/envs/seizure/libs/python312.lib\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from steps import setup_and_train_models, analyze_seizure_propagation\n",
    "import torch\n",
    "from datasetConstruct import construct_channel_recognition_dataset\n",
    "from models import Wavenet, train_using_optimizer\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-06T08:49:15.540307200Z",
     "start_time": "2025-03-06T08:48:55.763099300Z"
    }
   },
   "id": "8a6fb54970056190",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "RESULT_FOLDER = \"result\"\n",
    "MODEL_FOLDER = \"model\"\n",
    "model_names = ['Wavenet']  # 'CNN1D', 'Wavenet', 'LSTM', 'S4', 'ResNet'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-06T08:49:15.565443700Z",
     "start_time": "2025-03-06T08:49:15.546224Z"
    }
   },
   "id": "1f435e4429efe0ce",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Do batch analysis to find the best hyperparameters\n",
    "seizures = [1, 2, 3, 5, 7]\n",
    "thresholds = [0.8]\n",
    "smooth_windows = [80]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-06T08:49:15.567412Z",
     "start_time": "2025-03-06T08:49:15.555976600Z"
    }
   },
   "id": "a1e4cc19cfa56c01",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1491 ictal segments Ã— 96 channels\n"
     ]
    }
   ],
   "source": [
    "from steps import extract_sEEG_features\n",
    "from datasetConstruct import load_seizure_across_patients\n",
    "\n",
    "dataset = load_seizure_across_patients(data_folder='data')\n",
    "\n",
    "for seizure in dataset:\n",
    "    seizure_new = extract_sEEG_features(seizure, sampling_rate=seizure.samplingRate)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-03-06T08:49:18.093473500Z"
    }
   },
   "id": "c6cae63b9e3c480d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results, models = setup_and_train_models(\n",
    "    data_folder=\"data\",\n",
    "    model_folder=\"checkpoints\",\n",
    "    model_names=model_names,  # Only use CNN1D and Wavenet\n",
    "    train=True,\n",
    "    input_type='transformed',  # 'transformed' or 'raw'\n",
    "    params={'epochs': 100, 'batch_size': 4096, 'checkpoint_freq': 20},  # params: epochs, checkpoint_freq, lr, batch_size, device, patience, gradient_clip\n",
    "    hyperparameter_search=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40278f619e39dba2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "from utils import split_data, find_seizure_related_channels\n",
    "from datasetConstruct import load_single_seizure\n",
    "from models import output_to_probability\n",
    "from steps import extract_sEEG_features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "marking_file = 'data/Seizure_Onset_Type_ML_USC.xlsx'\n",
    "patient_no = 66\n",
    "seizure_no = 1\n",
    "data_folder = 'data'\n",
    "# Set up paths\n",
    "single_seizure_folder = os.path.join(data_folder, f\"P{patient_no}\")\n",
    "save_folder = os.path.join(\"result\", f\"P{patient_no}\", f\"Seizure{seizure_no}\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "model_name = model_names[0]\n",
    "model = models[model_name]\n",
    "params = {\n",
    "    'threshold': 0.8,\n",
    "    'smooth_window': 10,\n",
    "    'n_seconds': 60,\n",
    "    'seizure_start': 10,\n",
    "    'overlap': 0.9,\n",
    "    'device': 'cuda:0'\n",
    "}\n",
    "\n",
    "def load_seizure_data() -> Tuple[object, List[str], List[str]]:\n",
    "    \"\"\"Load seizure data and channel information\"\"\"\n",
    "    # Load seizure marking data\n",
    "    seizure_marking = pd.read_excel(marking_file)\n",
    "\n",
    "    # Find seizure-related channels\n",
    "    seizure_channels, seizure_onset_channels = find_seizure_related_channels(\n",
    "        seizure_marking, seizure_no, patient_no\n",
    "    )\n",
    "\n",
    "    # Load seizure data\n",
    "    seizure_obj = load_single_seizure(single_seizure_folder, seizure_no)\n",
    "    \n",
    "    if not hasattr(seizure_obj, 'ictal_transformed'):\n",
    "        seizure_obj = extract_sEEG_features(seizure_obj, sampling_rate=seizure_obj.samplingRate)\n",
    "\n",
    "    return seizure_obj, seizure_channels, seizure_onset_channels\n",
    "\n",
    "\n",
    "def process_data(seizure_obj) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    \"\"\"Process raw seizure data\"\"\"\n",
    "    fs = seizure_obj.samplingRate\n",
    "    if not hasattr(seizure_obj, 'ictal_transformed'):\n",
    "        ictal_data = seizure_obj.ictal_\n",
    "        preictal_data = seizure_obj.preictal2\n",
    "    \n",
    "        # Reshape and combine data\n",
    "        ictal_combined = ictal_data.reshape(-1, ictal_data.shape[2])\n",
    "        total_data = np.concatenate((preictal_data, ictal_combined), axis=0)\n",
    "    \n",
    "    else:\n",
    "        ictal_data = seizure_obj.ictal_transformed\n",
    "        preictal_data = seizure_obj.interictal_transformed\n",
    "        \n",
    "        # Reshape and combine data\n",
    "        ictal_combined = ictal_data.transpose(0, 2, 1, 3).reshape(ictal_data.shape[0]*ictal_data.shape[2], ictal_data.shape[1], ictal_data.shape[3])\n",
    "        preictal_data = preictal_data.transpose(0, 2, 1, 3).reshape(preictal_data.shape[0]*preictal_data.shape[2], preictal_data.shape[1], preictal_data.shape[3])\n",
    "        \n",
    "        total_data = np.concatenate((preictal_data, ictal_combined))\n",
    "\n",
    "    # Split data into windows\n",
    "    total_windows = split_data(total_data, 40, overlap=params['overlap'])\n",
    "\n",
    "    return total_data, total_windows, fs\n",
    "\n",
    "\n",
    "def compute_probabilities(data: np.ndarray, model, device: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute seizure probabilities for each channel.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : numpy.ndarray\n",
    "        Input data with shape (chunks, fs, channel) or (chunks, fs, channel, features)\n",
    "    model : torch model\n",
    "        The seizure detection model\n",
    "    device : str\n",
    "        The device to run the model on ('cpu' or 'cuda')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Probability matrix with shape (chunks, channel)\n",
    "    \"\"\"\n",
    "    # Determine if the input is 3D or 4D\n",
    "    is_4d = len(data.shape) == 4\n",
    "    \n",
    "    # Get dimensions\n",
    "    chunks = data.shape[0]\n",
    "    fs = data.shape[1]\n",
    "    n_channels = data.shape[2]\n",
    "    \n",
    "    # Initialize probability matrix\n",
    "    prob_matrix = np.zeros((chunks, n_channels))\n",
    "\n",
    "    for channel in range(n_channels):\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        if is_4d:\n",
    "            # 4D data: [chunks, fs, channel, features]\n",
    "            # Extract data for current channel\n",
    "            channel_data = data[:, :, channel, :]\n",
    "            \n",
    "            # Reshape for scaling: [chunks*fs, features]\n",
    "            original_shape = channel_data.shape\n",
    "            reshaped_data = channel_data.reshape(-1, original_shape[2])\n",
    "            \n",
    "            # Fit and transform the data\n",
    "            scaled_data = scaler.fit_transform(reshaped_data)\n",
    "            \n",
    "            # Reshape back\n",
    "            channel_data = scaled_data.reshape(original_shape)\n",
    "            \n",
    "            # Transpose for model input: [chunks, features, fs]\n",
    "            input_data = np.transpose(channel_data, (0, 2, 1))\n",
    "        else:\n",
    "            # 3D data: [chunks, fs, channel]\n",
    "            # Extract data for current channel\n",
    "            channel_data = data[:, :, channel]\n",
    "            \n",
    "            # Reshape for scaling: [chunks*fs, 1]\n",
    "            reshaped_data = channel_data.reshape(-1, 1)\n",
    "            \n",
    "            # Fit and transform the data\n",
    "            scaled_data = scaler.fit_transform(reshaped_data)\n",
    "            \n",
    "            # Reshape back to original shape and then to model input format\n",
    "            channel_data = scaled_data.reshape(chunks, fs)\n",
    "            input_data = channel_data.reshape(chunks, 1, fs)\n",
    "\n",
    "        # Convert to tensor and move to device\n",
    "        input_data = torch.tensor(input_data, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Compute probabilities\n",
    "        prob_matrix[:, channel] = output_to_probability(model, input_data, device)\n",
    "\n",
    "    return prob_matrix\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbe8d03956c9adb9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Test and debug single seizure data\n",
    "# Load data\n",
    "seizure_obj, seizure_channels, seizure_onset_channels = load_seizure_data()\n",
    "\n",
    "# Process data\n",
    "total_data, windowed_data, fs = process_data(seizure_obj)\n",
    "\n",
    "# Compute probabilities\n",
    "probabilities = compute_probabilities(windowed_data, model, params['device'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b1eb3857ad72287",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "channel = 31\n",
    "seconds = 60\n",
    "preictal_seconds = 10\n",
    "preictal_samples = int((60-preictal_seconds)/(1-params['overlap']))\n",
    "nsamples = int(seconds/(1-params['overlap'])) + preictal_samples\n",
    "raw_data_ictal = seizure_obj.ictal\n",
    "raw_data_preicatal = seizure_obj.interictal\n",
    "\n",
    "# Reshape the data\n",
    "raw_data_ictal = raw_data_ictal.reshape(-1, raw_data_ictal.shape[2])[:60*512]\n",
    "raw_data_preicatal = raw_data_preicatal.reshape(-1, raw_data_preicatal.shape[2])[-10*512:]\n",
    "\n",
    "# Combine the data\n",
    "raw_data = np.concatenate((raw_data_preicatal, raw_data_ictal), axis=0)\n",
    "raw_data = raw_data[:, channel]\n",
    "# Plot the total data and seizure probability\n",
    "feature_data = np.mean(windowed_data, axis=1)[:, channel][preictal_samples:nsamples]\n",
    "\n",
    "# Scale the raw data\n",
    "scaler = StandardScaler()\n",
    "feature_data = scaler.fit_transform(feature_data)\n",
    "probability = probabilities[:, channel][preictal_samples:nsamples]\n",
    "\n",
    "# Smooth the probability by using a moving average\n",
    "probability = np.convolve(probability, np.ones(params['smooth_window']) / params['smooth_window'], mode='same')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 6))\n",
    "ax[0].plot(raw_data)\n",
    "ax[1].plot(probability)\n",
    "ax[0].set_title(f'Channel {channel} - Raw Data')\n",
    "ax[1].set_title(f'Channel {channel} - Seizure Probability')\n",
    "# Set x-axis labels\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "# Change x-ticks to seconds\n",
    "x_ticks = np.arange(0, nsamples-preictal_samples, 100)\n",
    "x_labels = np.arange(0, seconds, 10)\n",
    "ax[1].set_xticks(x_ticks)\n",
    "ax[1].set_xticklabels(x_labels)\n",
    "\n",
    "# Delete ax[0] x-axis labels\n",
    "ax[0].set_xticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b073b8eee2345485",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate probability correlation to check the contamination of common noise\n",
    "from scipy.stats import pearsonr\n",
    "correlation = np.zeros((probabilities.shape[1], probabilities.shape[1]))\n",
    "for i in range(probabilities.shape[1]):\n",
    "    for j in range(probabilities.shape[1]):\n",
    "        correlation[i, j] = np.abs(pearsonr(probabilities[:, i], probabilities[:, j])[0])\n",
    "        \n",
    "plt.imshow(correlation)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6ff48104912f02",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results_propagation_total = []\n",
    "model_name = model_names[0]\n",
    "model = models[model_name]\n",
    "threshold = 0.8\n",
    "smooth_window = 10\n",
    "LOAD=False\n",
    "filename = f'{RESULT_FOLDER}/results_propagation_{model_name}_{threshold}_{smooth_window}.pkl'\n",
    "\n",
    "# if file exists\n",
    "if os.path.exists(filename) and LOAD:\n",
    "    with open(filename, 'rb') as f:\n",
    "        results_propagation_total = pickle.load(f)\n",
    "        \n",
    "if len(results_propagation_total) == 0:\n",
    "    for PAT_NO in [65, 66]:\n",
    "        for seizure_no in seizures:\n",
    "            if PAT_NO == 66 and seizure_no > 3:\n",
    "                continue\n",
    "            params = {\n",
    "                'threshold': threshold,\n",
    "                'smooth_window': smooth_window,\n",
    "                'n_seconds': 60,\n",
    "                'seizure_start': 10,\n",
    "            }\n",
    "            results_propagation = analyze_seizure_propagation(\n",
    "                patient_no=PAT_NO,\n",
    "                seizure_no=seizure_no,\n",
    "                model=model,\n",
    "                data_folder='data',\n",
    "                params=params,\n",
    "                save_results_ind=True\n",
    "            )\n",
    "            results_propagation_total.append(results_propagation)\n",
    "            \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(results_propagation_total, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14ccef415a934e81",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Examine the result:\n",
    "from plotFun import plot_eeg_style\n",
    "# 1. Plot the smoothed result:\n",
    "sample_result = results_propagation_total[5]['smoothed_probabilities'][20:350]\n",
    "sample_result2 = results_propagation_total[5]['probabilities'][20:300]\n",
    "fig = plot_eeg_style(sample_result.T, sampling_rate=5)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27e1254bfb1f8896",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Load and test the augmented data\n",
    "# augdata = pd.read_csv('data/clips.tar.gz', compression='gzip', header=0, sep=' ;', encoding='ISO-8859-2', quotechar='\"', engine='python')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b996c0c51c2e1a85",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seizure_channels_dataset_train, seizure_channels_dataset_val, seizure_onset_dataset_train, seizure_onset_dataset_val = construct_channel_recognition_dataset(results_propagation_total, 50, batch_size=128, data_aug=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26997a5ef8715da0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_seizure_channel = Wavenet(input_dim=1, output_dim=2, lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_loss, val_loss, val_accuracy = train_using_optimizer(model_seizure_channel, seizure_channels_dataset_train, seizure_channels_dataset_val, epochs=200, checkpoint_freq=20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28e4375eb57ea2fd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "\n",
    "x_ticks = range(0, 200, 20)\n",
    "\n",
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(x_ticks, val_loss, label='Validation')\n",
    "# Twin the y-axis for accuracy of validation\n",
    "plt.twinx()\n",
    "plt.plot(x_ticks, val_accuracy, label='Validation Accuracy', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('result/loss_seizure_channels.png')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64dde4dc9514e03f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predicted_labels_total = []\n",
    "\n",
    "time_lengths = [10, 20, 30, 40, 50, 60]\n",
    "\n",
    "for i in range(len(results_propagation_total)):\n",
    "\n",
    "    sample_seizure = results_propagation_total[i]['smoothed_probabilities'][50:300, :]\n",
    "    \n",
    "    # Feed the data to the model and get predictions\n",
    "    sample_seizure = sample_seizure.T\n",
    "    sample_seizure = np.expand_dims(sample_seizure, axis=1)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    sample_seizure = torch.tensor(sample_seizure, dtype=torch.float32)\n",
    "    \n",
    "    # Get the predictions\n",
    "    predictions = model_seizure_channel(sample_seizure)\n",
    "    \n",
    "    # Get the predicted labels, where predicted_labels = 1 when chance is more than 80%\n",
    "    predicted_labels = predictions.detach().to('cpu').numpy()\n",
    "    \n",
    "    predicted_labels = predicted_labels[:, 1] > 0.5\n",
    "    \n",
    "    predicted_labels_total.append(predicted_labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22895f03a8fee345",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Convert the channel from results_propagation to the y_true as 1s and 0s\n",
    "gound_truth_total = []\n",
    "for i in range(len(results_propagation_total)):\n",
    "    y_true = np.zeros(results_propagation_total[i]['smoothed_probabilities'].shape[1])\n",
    "    y_true[results_propagation_total[i]['true_seizure_channels']] = 1\n",
    "    gound_truth_total.append(y_true)\n",
    "    \n",
    "# Convert the gound_truth_total to a single array\n",
    "gound_truth_total = np.concatenate(gound_truth_total)\n",
    "\n",
    "# Convert the predicted_labels_total to a single array\n",
    "predicted_labels_total = np.concatenate(predicted_labels_total)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3093baf9d7c09ff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(gound_truth_total.flatten(), predicted_labels_total.flatten())\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig('result/confusion_matrix_seizure_channels.png')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c711468730b53833",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(gound_truth_total.flatten(), predicted_labels_total.flatten())\n",
    "precision = precision_score(gound_truth_total.flatten(), predicted_labels_total.flatten())\n",
    "recall = recall_score(gound_truth_total.flatten(), predicted_labels_total.flatten())\n",
    "f1 = f1_score(gound_truth_total.flatten(), predicted_labels_total.flatten())\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd869a20d7728b23",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "364f74876053c6f0",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
